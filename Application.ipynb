{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"apikey.json\"\n",
    "\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "from google.cloud import texttospeech\n",
    "from google.cloud import translate\n",
    "from PIL import Image\n",
    "\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class virtual_eyes:\n",
    "    \n",
    "    def __init__(self): #analzye_type; resim analizi için 0, yazı tanıma için 1\n",
    "        self.client = vision.ImageAnnotatorClient()\n",
    "        self.translate_client = translate.Client()\n",
    "        self.ttsclient = texttospeech.TextToSpeechClient()\n",
    "    \n",
    "    def take_a_photo(self):\n",
    "        try:\n",
    "            cap = cv.VideoCapture(0) # 0 indexli kameradan görüntü alıyoruz\n",
    "            ret, frame = cap.read() # kamera görüntüsünü alıyoruz\n",
    "            \n",
    "            b,g,r = cv.split(frame)\n",
    "            photo = cv.merge([r,g,b]) # bir nevi renklendirme yapıyoruz\n",
    "            cap.release()\n",
    "            cv.imwrite('takenphoto.jpg', photo) # resim dosya olarak kaydediliyor\n",
    "            return True # resim çekilip kaydedildi\n",
    "            #bunun düzeltilmesi gerekiyor, resmin dosya olarak kaydedilip sonra açılıp okunması yerine\n",
    "            #resmin sınıfı ve tipi, googlede kullanılacak olan tipe çevrilip döndürülmeli\n",
    "            #dönüşüm işlemini araştırmak lazım\n",
    "        except:\n",
    "            return False # hata çıktı demektir\n",
    "    \n",
    "    def make_analysis(self, analyze_type):\n",
    "        try:\n",
    "            with io.open(\"takenphoto.jpg\", 'rb') as image_file:\n",
    "                img = image_file.read()\n",
    "\n",
    "            image = types.Image(content=img)\n",
    "\n",
    "            for_return = \"\"\n",
    "            if analyze_type == 0: # resim analizi için\n",
    "                list_of_findings = []\n",
    "                response = self.client.label_detection(image=image)\n",
    "                for label in response.label_annotations:\n",
    "                    list_of_findings.append(label.description)\n",
    "                # çeviri işlemleri burada yapılacak\n",
    "                # önemine göre kelimeler burada listeden çıkarılabilir\n",
    "                for_return = self.translate_texts(list_of_findings)\n",
    "            else:\n",
    "                list_of_findings = []\n",
    "                response = self.client.text_detection(image=image)\n",
    "                for text in response.text_annotations:\n",
    "                    list_of_findings.append(text.description)\n",
    "                # düzeltme işlemleri burada yapılacak\n",
    "                for_return = ' '.join(list_of_findings)\n",
    "\n",
    "            return for_return # return edilecek şey bir string değişken olacak (çıkarımlar, yada yazılar)\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def translate_texts(self, list_of_texts):\n",
    "        text = ', '.join(list_of_texts)\n",
    "        # çevirisi yapılacak dil Türkçe için tr\n",
    "        target = 'tr'\n",
    "        # kaynak dil\n",
    "        source = 'en'\n",
    "        \n",
    "        translation = self.translate_client.translate(text, source_language=source, target_language=target)\n",
    "\n",
    "        return translation['translatedText'] # çevrilen yazı cümle olarak çevrilir\n",
    "    \n",
    "    def text_to_speech(self, text):\n",
    "        try:\n",
    "            synthesis_input = texttospeech.types.SynthesisInput(text=text)\n",
    "            voice = texttospeech.types.VoiceSelectionParams(\n",
    "                language_code='tr-TR',\n",
    "                ssml_gender=texttospeech.enums.SsmlVoiceGender.NEUTRAL)\n",
    "            \n",
    "            audio_config = texttospeech.types.AudioConfig(\n",
    "                audio_encoding=texttospeech.enums.AudioEncoding.MP3)\n",
    "            \n",
    "            response = self.ttsclient.synthesize_speech(synthesis_input, voice, audio_config)\n",
    "            \n",
    "            # output.mp3 oluşturulacak dosya\n",
    "            with open('output.mp3', 'wb') as out:\n",
    "                out.write(response.audio_content)\n",
    "            \n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "            \n",
    "    def display_the_speech(self, speech):\n",
    "        try:\n",
    "            os.startfile(speech)\n",
    "            return True\n",
    "        except:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "va = virtual_eyes()\n",
    "ret = va.take_a_photo()\n",
    "if ret:\n",
    "    returned_text = va.make_analysis(1)\n",
    "    \n",
    "    if returned_text != None:\n",
    "        ret2 = va.text_to_speech(returned_text)\n",
    "        \n",
    "        if ret2:\n",
    "            ret3 = va.display_the_speech('output.mp3')\n",
    "            \n",
    "            if ret3 == False: print(\"Ses Çalmada Hata\") \n",
    "        else: print(\"Yazı Seslendirmede Hata\")\n",
    "    else: print(\"Resim Analizinde Hata\")\n",
    "else: print(\"Resim Çekmede Hata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
